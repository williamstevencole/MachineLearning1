{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91329a4b",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edca2e21",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split, GridSearchCV\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler, OneHotEncoder\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import joblib\n",
    "\n",
    "RANDOM_STATE = 101\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65071e81",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebde8ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m CSV_PATH = \u001b[33m\"\u001b[39m\u001b[33mfiles/train.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      2\u001b[39m TARGET = \u001b[33m\"\u001b[39m\u001b[33mSalePrice\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m df = \u001b[43mpd\u001b[49m.read_csv(CSV_PATH)\n\u001b[32m      5\u001b[39m df.head(\u001b[32m20\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "CSV_PATH = \"files/train.csv\"\n",
    "TARGET = \"SalePrice\"\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f82ac9",
   "metadata": {},
   "source": [
    "# Data exploration to see structure, statictics and correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aab8fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info() # Display structure of the DataFrame\n",
    "#display(df.describe().T.head(20)) # Display first 20 rows of statistical summary\n",
    "\n",
    "if 'PID' in df.columns:\n",
    "  df = df.drop(columns=[\"PID\"])\n",
    "\n",
    "num_corr = df.select_dtypes(include=np.number).corr(numeric_only=True)\n",
    "sns.heatmap(num_corr, cmap=\"coolwarm\", center=0)\n",
    "plt.title(\"Numerical Feature Correlation Heatmap\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "corr_target = num_corr[TARGET].dropna().sort_values(ascending=False)\n",
    "\n",
    "# Identify top 5 features most correlated with the target variable\n",
    "top_corr_features = corr_target.index.tolist()[1:6]\n",
    "\n",
    "# Identify  bottom 5 features least correlated with the target variable\n",
    "bottom_corr_features = corr_target.index.tolist()[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fff131",
   "metadata": {},
   "source": [
    "# Dispersion graphs of most correlated variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75031daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in top_corr_features:\n",
    "    sns.scatterplot(data=df, x=col, y=TARGET)\n",
    "    plt.title(f\"{col} vs {TARGET}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5237175",
   "metadata": {},
   "source": [
    "# Dispersion graphs of less correlated variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6e8086",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in bottom_corr_features:\n",
    "    sns.scatterplot(data=df, x=col, y=TARGET)\n",
    "    plt.title(f\"{col} vs {TARGET}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca793024",
   "metadata": {},
   "source": [
    "# Elimination of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e92bbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_iqr(df, cols, k=1.5):\n",
    "    \"\"\"Remove outliers from specified columns using the IQR method\"\"\"\n",
    "    mask = pd.Series(True, index=df.index)\n",
    "    for col in cols:\n",
    "      if col not in df.columns or not np.issubdtype(df[col].dropna().dtype, np.number):\n",
    "        continue\n",
    "      q1 = df[col].quantile(0.25)\n",
    "      q3 = df[col].quantile(0.75)\n",
    "      iqr = q3 - q1\n",
    "      lower_bound = q1 - k * iqr\n",
    "      low, high = q1 - k*iqr, q3 + k*iqr\n",
    "      mask &= df[col].between(lower_bound, high) | df[col].isna()\n",
    "    return df[mask]\n",
    "\n",
    "before = len(df)\n",
    "df_filtered = remove_outliers_iqr(df, top_corr_features)\n",
    "after = before - len(df_filtered)\n",
    "ratio = after / before if before > 0 else 0\n",
    "\n",
    "print(f\"Removed {after} outliers from the dataset.\")\n",
    "\n",
    "if ratio > 0.12:\n",
    "    print(\"Warning: More than 12% of data removed as outliers. Consider reviewing the outlier removal process.\")\n",
    "else:\n",
    "    df = df_filtered\n",
    "    print(f\"Dataset size after outlier removal: {len(df)} rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d76c67",
   "metadata": {},
   "source": [
    "# Null Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee4a621",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_percent = df.isnull().mean() * 100\n",
    "display(null_percent[null_percent > 0].sort_values(ascending=False).head(15))\n",
    "\n",
    "cols_to_drop = null_percent[null_percent > 50].index.tolist()\n",
    "if cols_to_drop:\n",
    "    df = df.drop(columns=cols_to_drop)\n",
    "    print(f\"Eliminated columns that have >50% null values: {cols_to_drop}\")\n",
    "else:\n",
    "    print(\"No columns with >50% null values found.\")\n",
    "\n",
    "\n",
    "for c in df.select_dtypes(include=[np.number]).columns:\n",
    "    if df[c].isnull().any():\n",
    "        df[c] = df[c].fillna(df[c].median())\n",
    "\n",
    "# Categóricas -> valor más frecuente\n",
    "for col in df.select_dtypes(exclude=[np.number]).columns:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d95e54",
   "metadata": {},
   "source": [
    "# training validation split (90/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2a8b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[TARGET])\n",
    "y = df[TARGET]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23697b77",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee705fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = X_train.select_dtypes(include=np.number).columns.tolist()\n",
    "cat_cols = X_train.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "# Preprocessing pipelines for numerical and categorical data\n",
    "num_pipeline = Pipeline([\n",
    "  (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "  (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "  (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "  (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "  (\"num\", num_pipeline, num_cols),\n",
    "  (\"cat\", cat_pipeline, cat_cols)\n",
    "])\n",
    "\n",
    "model = ElasticNet(max_iter=50000, random_state=RANDOM_STATE)\n",
    "\n",
    "pipe = Pipeline([\n",
    "  (\"preprocessor\", preprocessor),\n",
    "  (\"model\", model)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e467ca",
   "metadata": {},
   "source": [
    "# Hyperpamaters search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02371ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "  \"model__alpha\":[0.1, 1, 5, 10, 50, 100],\n",
    "  \"model__l1_ratio\":[0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1.0]\n",
    "}\n",
    "\n",
    "# Hyperparameter tuning with GridSearchCV\n",
    "gridsearch = GridSearchCV(\n",
    "  estimator=pipe,\n",
    "  param_grid=param_grid,\n",
    "  scoring=\"neg_mean_absolute_error\",\n",
    "  cv=5,\n",
    "  n_jobs=-1,\n",
    ")\n",
    "gridsearch.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Hyperparameters:\", gridsearch.best_params_)\n",
    "print(\"Best CV Score (neg_MSE):\", gridsearch.best_score_)\n",
    "\n",
    "best_model = gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71e0508",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7578598",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_val)\n",
    "\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Validation MAE: {mae:.2f}\")\n",
    "print(f\"Validation MSE: {mse:.2f}\")\n",
    "print(f\"Validation RMSE: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58c7795",
   "metadata": {},
   "source": [
    "# Result visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babb01d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(y_val, y_pred, alpha=0.7)\n",
    "plt.xlabel(\"Actual SalePrice\")\n",
    "plt.ylabel(\"Predicted SalePrice\")\n",
    "plt.title(\"Actual vs Predicted SalePrice\")\n",
    "lims = [min(y_val.min(), y_pred.min()), max(y_val.max(), y_pred.max())]\n",
    "plt.plot(lims, lims, color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e1f27b",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9076e9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(best_model, \"model/elasticnet_model.joblib\")\n",
    "\n",
    "pd.DataFrame({\"y_true\": y_val, \"y_pred\": y_pred}).to_csv(\"model/val_predictions.csv\", index=False)\n",
    "X_val_copy = X_val.copy()\n",
    "X_val_copy[TARGET] = y_val\n",
    "X_val_copy.to_csv(\"model/X_val_with_target.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
