üè† EXAMEN FINAL INTEGRADOR - OPCI√ìN B (Regresi√≥n)

Catedr√°tica: Ing. Nicole Rodr√≠guez Tema: Feature Engineering Geogr√°fico + Ensambles de Regresi√≥n

Contexto del Negocio: Una agencia de bienes ra√≠ces en California quiere modernizar su sistema de valuaci√≥n. Tienen datos hist√≥ricos (habitaciones, antig√ºedad, ingresos de la zona, latitud, longitud). El problema es que la Ubicaci√≥n (Latitud/Longitud) es dif√≠cil de entender para un modelo lineal simple. Tu misi√≥n es:

    Usar Clustering para agrupar las casas en "Vecindarios" basados en sus coordenadas.

    Usar esos "Vecindarios" como una nueva caracter√≠stica para entrenar un modelo de Ensamble (Stacking) que prediga el precio exacto de la vivienda.

Dataset:

    Fuente: California Housing Prices (Kaggle)

    Archivo: housing.csv

    Target: median_house_value

Instrucciones T√©cnicas (housing_master.py):

    Limpieza y EDA:

        Carga con argparse.

        Manejo de nulos (si los hay).

        Codifica la columna ocean_proximity (OneHotEncoder).

    Ingenier√≠a de Caracter√≠sticas (El Truco Pro):

        Antes de dividir los datos, usa K-Means sobre las columnas latitude y longitude para crear, por ejemplo, 10 clusters (Vecindarios).

        Agrega la columna cluster_location al dataframe. ¬°Ahora el modelo sabr√° en qu√© "zona" est√° la casa!

    Modelado (Stacking Regressor):

        Queremos predecir el precio num√©rico.

        Implementa un StackingRegressor:

            Nivel 1: SVR (Kernel RBF) y Random Forest Regressor.

            Nivel 2 (Final): Linear Regression (o Ridge).

    Evaluaci√≥n:

        Calcula el RMSE (Ra√≠z del Error Cuadr√°tico Medio) y R2 Score.

        Grafica: Valores Reales vs. Valores Predichos (Un scatter plot donde una l√≠nea diagonal perfecta significar√≠a predicci√≥n perfecta).