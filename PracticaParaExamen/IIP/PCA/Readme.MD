üìã EXAMEN PARCIAL - PR√ÅCTICO (PCA)

Catedr√°tica: Ing. Nicole Rodr√≠guez Tema: Reducci√≥n de Dimensionalidad (PCA)

Contexto del Negocio: Un laboratorio m√©dico tiene un dataset de C√°ncer de Mama con 30 caracter√≠sticas num√©ricas extra√≠das de im√°genes digitales (radio, textura, per√≠metro, √°rea, suavidad, etc.). Los m√©dicos no pueden visualizar gr√°ficos de 30 dimensiones. Te contratan para reducir esta complejidad a 2 Dimensiones para poder ver en una pantalla plana si los tumores Malignos y Benignos se separan visualmente.

Dataset: Descarga el dataset Breast Cancer Wisconsin (Diagnostic): üîó Link Kaggle: Breast Cancer Wisconsin (Archivo: data.csv)

Instrucciones T√©cnicas:

Desarrolla el script pca_exam.py modular:

    Limpieza y EDA:

        Carga los datos con argparse.

        Elimina la columna id y Unnamed: 32 (si existen).

        La columna diagnosis es tu target (M/B). Sep√°rala en y. El resto es X.

        Muestra un Heatmap de Correlaci√≥n de las 30 variables (ver√°s que es un caos y hay mucha redundancia, justificando el uso de PCA).

    Pipeline de PCA:

        Crea un Pipeline con:

            StandardScaler (Obligatorio).

            PCA(n_components=2).

        Aplica el pipeline a X.

    An√°lisis de Varianza:

        Accede al objeto PCA dentro del pipeline.

        Imprime: "Varianza explicada por cada componente".

        Imprime: "Varianza total acumulada" (La suma). ¬øEs suficiente informaci√≥n? (Usualmente > 80% es bueno, > 60% es aceptable para visualizaci√≥n).

    Visualizaci√≥n 2D:

        Crea un DataFrame con los resultados del PCA (Componente 1, Componente 2).

        Agrega la columna diagnosis a ese DataFrame.

        Genera un Scatter Plot:

            Eje X: Componente 1.

            Eje Y: Componente 2.

            Color (hue): Diagnosis (M vs B).

        Objetivo: Deber√≠as ver dos grupos claramente separados, demostrando que PCA funcion√≥.
